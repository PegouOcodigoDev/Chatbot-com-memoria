# Chatbot Virtual com Langchain

Este √© um projeto de chatbot virtual criado com a biblioteca **LangChain**, **Streamlit**, e diferentes modelos de IA, como o **Hugging Face Hub**, **Ollama**, e **OpenAI GPT**. O chatbot √© projetado para fornecer respostas em portugu√™s e pode ser facilmente personalizado para responder a diferentes tipos de perguntas.

## Tecnologias Utilizadas

- **Streamlit**: Framework para cria√ß√£o de interfaces interativas de dados.
- **LangChain**: Framework de Python para facilitar o desenvolvimento de pipelines de IA com LLMs (Modelos de Linguagem de Grande Escala).
- **HuggingFaceHub**: Interface para acessar modelos hospedados no Hugging Face Hub.
- **Ollama**: Biblioteca para integrar o modelo de IA Ollama.
- **OpenAI**: Biblioteca para acessar os modelos de IA da OpenAI.
- **dotenv**: Para carregamento de vari√°veis de ambiente do arquivo `.env`.

## Como Come√ßar

Siga os passos abaixo para executar o chatbot localmente.

### 1. Clonar o reposit√≥rio

```bash
git clone https://github.com/seu-usuario/chatbot-virtual.git
cd chatbot-virtual
```

### 2. Criar o ambiente virtual com Poetry

Recomenda-se usar o **Poetry** para gerenciar as depend√™ncias e o ambiente virtual:

```bash
poetry install
```

### 3. Ativar o ambiente virtual

Para ativar o ambiente virtual criado pelo Poetry, execute:

```bash
poetry shell
```

### 4. Instalar as depend√™ncias

As depend√™ncias do projeto ser√£o instaladas automaticamente durante o comando `poetry install`, mas voc√™ tamb√©m pode instalar manualmente com:

```bash
poetry add <nome_da_depend√™ncia>
```

### 5. Configurar as vari√°veis de ambiente

Crie um arquivo `.env` na raiz do projeto e adicione suas chaves de API para o Hugging Face (Hugging Face API Key) ou outros servi√ßos que voc√™ deseja utilizar:

```env
HUGGINGFACE_API_KEY=your_huggingface_api_key
```

### 6. Executar o aplicativo

Execute o aplicativo Streamlit com o comando abaixo:

```bash
streamlit run chatbot.py
```

Isso abrir√° o aplicativo do chatbot no seu navegador.

## Estrutura do Projeto

- **chatbot.py**: Arquivo principal que configura a interface com o usu√°rio utilizando o Streamlit e interage com o modelo de IA.
- **chain.py**: Cont√©m a l√≥gica para gerar a resposta do chatbot, incluindo a cria√ß√£o do prompt e intera√ß√£o com o modelo de IA.
- **model.py**: Define as classes para instanciar os modelos de IA, como o HuggingFaceHub, Ollama, e OpenAI.
- **.env**: Arquivo para armazenar as vari√°veis de ambiente, como chaves de API.

## Como Funciona

1. O usu√°rio envia uma mensagem via interface do **Streamlit**.
2. A mensagem √© processada e enviada para a fun√ß√£o `generate_response` em **chain.py**.
3. A fun√ß√£o `generate_response` cria um prompt com o hist√≥rico da conversa e envia a consulta ao modelo de IA apropriado.
4. O modelo de IA retorna uma resposta que √© exibida para o usu√°rio via **Streamlit**.

## Personaliza√ß√£o

Voc√™ pode facilmente modificar o tipo de modelo de IA a ser utilizado no arquivo `model.py`. Basta ajustar o par√¢metro `model_type` ao inicializar o **FactoryModel** no arquivo `chain.py`:

- `"hf_hub"`: Para usar modelos do Hugging Face.
- `"ollama"`: Para usar o modelo Ollama.
- `"openai"`: Para usar o modelo da OpenAI.

## Imagens
[](https://github.com/PegouOcodigoDev/Chatbot-com-memoria/blob/main/Seu%20assistente%20virtual.pdf)

## Contribui√ß√µes

Sinta-se √† vontade para fazer contribui√ß√µes! Se voc√™ tiver alguma sugest√£o ou corre√ß√£o, envie um pull request ou abra um issue.

---

Obrigado por usar o chatbot virtual! ü§ñüí¨
